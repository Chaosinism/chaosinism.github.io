{"categories":[{"title":"经验心得","uri":"https://chaosinism.github.io/categories/%E7%BB%8F%E9%AA%8C%E5%BF%83%E5%BE%97/"},{"title":"自制工具","uri":"https://chaosinism.github.io/categories/%E8%87%AA%E5%88%B6%E5%B7%A5%E5%85%B7/"},{"title":"长期更新","uri":"https://chaosinism.github.io/categories/%E9%95%BF%E6%9C%9F%E6%9B%B4%E6%96%B0/"}],"posts":[{"content":"自动为绘画线稿生成3D信息，从而自动计算光影，这是我持续在关注的一种技术。一直想系统地介绍一下，但不知从哪里说起。今天先简单介绍其中一种方法。\n  法线/置换贴图与使用后的效果（线稿来自《碧蓝幻想》美术设定集）\n  \n法线贴图 法线贴图(Normal Map)利用贴图每个像素的RGB值储存该点的三维法线矢量，然后拿它来计算贴图表面的光线反射，这样低多边形的3D模型也能体现出光照细节。人们经常用它来改善游戏中的3D材质。\n不过我更关心的是另一种应用——对于一张绘画线稿，如果也能得到一张法线贴图，就能自动计算其光影，从而省去很多手动上色的步骤。V-Sense研究小组曾在下面的论文中提出利用深度学习生成法线贴图的方法：\n Hudon, Matis, Mairéad Grogan, and Aljosa Smolic. \u0026ldquo;Deep normal estimation for automatic shading of hand-drawn characters.\u0026rdquo; Proceedings of the European Conference on Computer Vision (ECCV). 2018.\n 论文的成果就是开源项目DeepNormals，虽然它看起来不太受学术界关注，但我个人的使用体验倒是很不错，强过不少更热门的自动上色方案。\n高度图/置换贴图 最近，DeepNormals的作者发表了一篇后续文章，提出在生成法线贴图后可以进一步将其转化为高度图：\n Hudon, Matis, et al. \u0026ldquo;Augmenting Hand-Drawn Art with Global Illumination Effects through Surface Inflation.\u0026rdquo; European Conference on Visual Media Production. 2019.\n 高度图可以作为置换贴图(Displacement Map)，贴图的每个点会沿法线进行位移，从而造成真实的三维凹凸效果。这种方法能做到一些法线贴图无法做到的事：\n 法线贴图没有自阴影，而置换法支持； 可以用图形学模拟距离感相关的技法，如镜头虚化和色彩远近法； 置换后可以在立体空间小幅旋转图片而不产生违和感，甚至可以由此将2D图片转为3D模型。  当然它也有缺点，比如运算慢，但是如果我们考虑将其应用于绘画/动画而非实时渲染，这一点就不是特别重要了，因此我还是很愿意学习这个方法的。\n算法 对于如何生成这样的高度图，论文中给出的算法其实很简单粗暴。假设$(u,v)$为贴图坐标，相应的高度为$Z(u,v)$（也就是待求量），那么沿$u$方向可以计算出切线向量\n$\\mathbf{t}_{uv}^{\\parallel}=[1,0,\\frac{dZ(u,v)}{du}]$，用离散形式表示其实就是\n$\\mathbf{t}_{uv}^{\\parallel}=[1,0,Z(u+1,v)-Z(u,v)]$；同理，沿$u$方向可以计算出另一个切线向量\n$\\mathbf{t}_{uv}^{\\perp}=[0,1,Z(u,v+1)-Z(u,v)]$。\n我们已经知道了贴图每个点的法线向量$\\mathbf{n}_{uv}$，它应当与两个切线都垂直，即点乘得0。于是定义一个“能量”函数：\n$E=\\sum_{u,v} (\\mathbf{t}^{\\parallel}\\cdot\\mathbf{n})^2+(\\mathbf{t}^{\\perp}\\cdot\\mathbf{n})^2$\n函数的值越小就说明高度图越准确。它对$Z(u,v)$的偏导只含一次项，用梯度下降之类的方法很容易进行优化。\n自制脚本 根据论文的说法，这个算法早就有了，奇怪的是我以前也考察过一些能转换法线和高度图的工具，比如AwesomeBump或GIMP法线贴图插件，它们都没有使用这种方法，而是只沿一个方向由法线累计高度，误差要大很多，不太清楚其中的缘由。\n这一篇新论文自身也并没有附带开源代码，所幸算法简单，于是我用Scipy的优化器自己实现了一下，放在下面这个仓库。以后再有计算法线相关的内容可能也会在这里更新：\nhttps://github.com/Chaosinism/NormalMapTool\n","id":0,"section":"posts","summary":"\u003cp\u003e自动为绘画线稿生成3D信息，从而自动计算光影，这是我持续在关注的一种技术。一直想系统地介绍一下，但不知从哪里说起。今天先简单介绍其中一种方法。\u003c/p\u003e","tags":["Python"],"title":"由法线贴图生成高度图的算法","uri":"https://chaosinism.github.io/posts/normals-to-height/","year":"2020"},{"content":"很久之前写过一个利用IBM Watson的语音识别服务制作UTAU音源的脚本，当时效果不太理想，但我自己一直没有制作音源的需要，就没再更新过。后来陆续有人问，所以不能再装死了，在这里做一些补充说明。\nIBM Watson的改动 首先，IBM Watson改变了检查用户凭证的方式，与上一篇文章发布时相比主要有以下两项改动：\n “用户名：密码”的验证被API密钥验证代替。 每个用户现在具有不同的URL地址。  新版的curl命令格式与用户凭证的获得方式都可以在IBM提供的入门教程中找到，看到下图这个页面就说明顺利找到了：\n  新版凭证\n   另一个改动是好消息——语音识别的免费额度提升到了每月500分钟，单个文件的大小限制为100M。注意如果文件没有达到100M就被提示体积过大，很有可能是上面提到的URL输入错误，请对照入门教程检查一下。\nPython脚本更新 IBM返回JSON文件标记语音中每个单词的位置，我之前写了Python脚本由此提取单音的音频，后来发现许多单音的时长相当短，基本无法在UTAU中使用，所以本次增加了一个参数——时长阈值，可以与之前的语音识别置信度阈值共同使用，过滤掉无用的单音。\n音源在UTAU中的后续处理 要令UTAU正常工作，除单音音频外还需要配置文件，包含oto.in与frq文件。我没有写这部分的脚本，因为有多种现成的解决方案。\n  自动计算oto与frq的隐藏按钮\n   首先UTAU自身就带有自动推算参数的功能，但是启动该功能的按钮是隐藏的，在上图所示位置。\n此外有不少人开发了自己的工具，以下网站列举了其中一部分：\n https://w.atwiki.jp/vbmaker/pages/23.html\n https://utaforum.net/\n  也可以看这位UP主的中文教程，个人认为讲得比较清楚。\n","id":1,"section":"posts","summary":"\u003cp\u003e很久之前写过一个\u003ca href=\"/posts/voice-extraction\"\u003e利用IBM Watson的语音识别服务制作UTAU音源的脚本\u003c/a\u003e，当时效果不太理想，但我自己一直没有制作音源的需要，就没再更新过。后来陆续有人问，所以不能再装死了，在这里做一些补充说明。\u003c/p\u003e","tags":["UTAU","机器学习","Python"],"title":"AI辅助制作音源的补充说明","uri":"https://chaosinism.github.io/posts/voice-extraction-2/","year":"2020"},{"content":"自制了一个工具用来统计B站视频评论区数据。\n开发动机 曾经B站的评论区可以查看哪一些评论被因为什么原因删除，后来这个功能被取消了，同时连评论的楼层编号也不显示了，因此间接推断有多少评论被删除都变为不可能。我认为这样很野蛮，所以做了一个工具遍历指定视频的每条评论，然后就能统计中间缺了多少条。\n做完发现凡是稍有热度的视频就很少有评论完好无损的，可惜进一步分析评论消失的原因已经做不到了。\n因为想要继续练习Godot游戏引擎，就用它来实现了这个工具，结果生成的可执行文件似乎耗用了不少多余的体积。另外本来也想做HTML5的在线版，但不知道怎么绕过跨域访问的限制，所以暂时还是只有Windows版。\n功能介绍   软件界面\n   目前的主要功能：\n 统计指定视频的楼层数，并计数缺失的楼层，来推断有多少评论被举报或删除。 展示评论的时间分布。 按评论条数对评论人排序，并链接到他们的个人空间页面。 导出包含所有评论信息的JSON文件。  已知的限制：\n 无法得知评论消失的原因（相关API已被B站取消）。 下载评论需要一定时间——评论文件并不小，1000条评论就有可能超过1M大小，请尽量避免分析评论数量极多的视频。  未知的限制：\n 尚不知道B站是否\\如何限制API的频繁调用。  发布信息 源码\n可执行文件（目前支持Windows系统）\n","id":2,"section":"posts","summary":"\u003cp\u003e自制了一个工具用来统计B站视频评论区数据。\u003c/p\u003e","tags":["Godot"],"title":"Bilibili评论统计工具","uri":"https://chaosinism.github.io/posts/comment-analyzer/","year":"2020"},{"content":"今天将网站主题更换成了Hugo Theme Pure，比起原先的主题，内容分类更清晰一些，还有站内搜索之类的新功能。\n另外因为评论系统是半手动的，我又经常抽不出时间，所以站内评论的显示和回复都比较慢，如果有急事还是不要指望这个了。\n","id":3,"section":"posts","summary":"今天将网站主题更换成了Hugo Theme Pure，比起原先的主题，内容分类更清晰一些，还有站内搜索之类的新功能。 另外因为评论系统是半手动的，我又经常","tags":[],"title":"网站主题更新","uri":"https://chaosinism.github.io/posts/theme-update/","year":"2020"},{"content":"第五届“Touhou Fan Game Jam”72小时制作赛的参赛体验和作品。实际上由于活动不到周末就开始了，只有两天可以用来进行制作，到最后各方面完成度都较为有限。\n作品简介   除《东方Project》外，本次活动要求的游戏主题是民俗、传说或神话（Folklore, Myths, and Legends），正好春节快到了，就以此为题，以系列中的中国角色红美铃、霍青娥与纯狐作为NPC，吉吊八千慧作为敌人。大致背景是春节举行烟花大会，同时几位NPC竞争谁能提供最精彩的表演，而灵梦与吉吊以此打赌来试图赚钱。游戏过程中，玩家可以给不同角色下注，同时也能参与弹幕战斗来提高该角色评价，或反过来攻击观众来降低角色评价，这些都以赚到最多钱为目的。\n游戏地址和源码提供如下：\n 参赛页面\n 游戏本体\n 源代码\n  制作体验 机制设计 游戏主要分为交易的部分和弹幕射击的部分，之所以这样设置的理由如下：\n  交易部分好像和东方比较格格不入，主要是我尚未制作过回合制游戏，想借机尝试一下。至于具体玩法，在桌面游戏中有一个“Investment”机制，它不像主流战略或经营游戏那样让玩家始终控制同一个势力，而是允许玩家在不同的势力之间下注投资，玩过不同题材的采用这种机制的游戏都感觉不错，如《1830》《Imperial》《Mombasa》还有一个最近关注的《Pax Renaissance》。但电子游戏好像就不常见到这种设置，于是好奇想自己试试。\n当然实现出来效果就没有想得那么好了，因为缺少时间测试。可以考虑的改进方案有设置多名对手、引入隐藏信息和非线性价格变化等，不过多半不会真的去改进。\n  弹幕部分没有想太多，只是觉得既然是东方就应该有弹幕。另外这段时间跟别人合作的东西里可能会涉及到弹幕战斗，所以顺便也练习了一下。\n工具 此游戏的制作流程与之前的Ludum Dare 45基本相同，使用Godot 3.1作为游戏引擎，GIMP处理美术，LMMS编曲。唯一不同的大概是画图时用了Clip Studio Paint，但是所有美术资源都是点阵图，用什么工具画估计都差不多。\n这次在线版游戏的托管不再是Github，而是Itch.io——因为活动是在这里举办的。初步尝试后感觉其功能对游戏制作者来说比较方便，游戏简介、托管、下载、反馈等所有必要的功能都很容易设置，之后如果还有时间做游戏可能仍会考虑在此发布。\n总结 本次参加活动的体验并不是特别美好，最初的目的是锻炼自己的实践能力，但是实际上受到了好几个因素的制约：\n 由于规则所限，不能最大程度利用优秀的共享素材，经常要“重造轮子”； 作品完成度有限，尚未能判断想要检验的新想法是否真的可行； 短时间内赶制的素材与代码质量很低，难以回收再利用。  这样看来，借Game Jam来练习的效率有限，以后可能要改变期望，比如遇到感兴趣的主题再参加。\n","id":4,"section":"posts","summary":"\u003cp\u003e第五届“Touhou Fan Game Jam”72小时制作赛的参赛体验和作品。实际上由于活动不到周末就开始了，只有两天可以用来进行制作，到最后各方面完成度都较为有限。\u003c/p\u003e","tags":["Godot","LMMS","独立游戏","东方Project"],"title":"Touhou Fan Game Jam 5 参赛体验","uri":"https://chaosinism.github.io/posts/thjam5/","year":"2020"},{"content":" 本页面收录了我在各种场合制作的一些小游戏，或许可以用于取乐。其中多数游戏的代码与美术\\音乐素材是开源的，欢迎分享与交流。     名称 游戏链接 源码链接 引擎 简介     Islanders GitHub GitHub Construct 2 Ludum Dare 38届参赛作品。完成度很低，虽然放出来了，但不建议玩。\n比赛页面   Knights and Kings GitHub GitHub Construct 2 Ludum Dare 40届参赛作品。大概比上面那个好一点。\n比赛页面   Aqours海之家 GitHub  Construct 2 《Love Live! Sunshine!!》 同人游戏。\n视频介绍(BiliBili)   Life with Words GitHub GitHub Godot Ludum Dare 45届参赛作品。\n比赛页面 / 视频介绍(BiliBili)   《创人药》之人机杂交 GitHub GitHub TensorFlow.js ，，，\n介绍页面   Spring Festival in Gensokyo Itch.io GitHub Godot Touhou Fan Game Jam 5届参赛作品。\n介绍页面 / 比赛页面   ","id":5,"section":"posts","summary":"\u003cul\u003e\n\u003cli\u003e本页面收录了我在各种场合制作的一些小游戏，或许可以用于取乐。其中多数游戏的代码与美术\\音乐素材是开源的，欢迎分享与交流。\u003c/li\u003e\n\u003c/ul\u003e","tags":["资源汇总","Godot","JavaScript","独立游戏"],"title":"在线小游戏","uri":"https://chaosinism.github.io/posts/tiny-games/","year":"2019"},{"content":"最近感觉我们的创主独人13愈发整不出活了，于是打算用AI来代劳一下，就做了下面这个应用，利用机器学习来自动生成《创人药》。\n点击这里使用\n转载请注明作者“独人13”，谢谢，，，\n原理介绍 这里使用流行的方法递归神经网络（Recurrent Neural Network, RNN）与长短期记忆（Long Short-Term Memory，LSTM），给定一个序列（具体到这里就是文本），可以预测出它的下一位（即下一个字），重复这个过程就能生成出完整的句子。\n用作训练的数据是独人老师以往的文章，主要写于2011到2013年，近年的新作也是有的，如《骗子的臭味》等，加起来大小约为850Kb，感觉数据还是不太充足，但也找不到更多材料了。我这次试用Google Colab来在Google的云上训练它，发现居然比自己的电脑还快，，，\n为了把它变成一个在线应用，利用了TensorFlow.js，即TensorFlow的Javascript实现，被它转换后的模型可以直接在浏览器运行，似乎完成度很高的样子，开发者不需要关注太多细节就能实现想要的功能。\n还有一个小问题，就是上面介绍的这些工具我全都不会用。所以还是发扬传统艺能，找别人现成的东西缝合一下。主要借鉴了以下的文章和代码。\n参考资料 https://www.tensorflow.org/tutorials/text/text_generation\nhttps://leemeng.tw/how-to-generate-interesting-text-with-tensorflow2-and-tensorflow-js.html\nhttps://codepen.io/caisq/pen/vrxOvy\n","id":6,"section":"posts","summary":"\u003cp\u003e最近感觉我们的创主\u003ca href=\"https://www.weibo.com/u/6729213800\"\u003e独人13\u003c/a\u003e愈发整不出活了，于是打算用AI来代劳一下，就做了下面这个应用，利用机器学习来自动生成《创人药》。\u003c/p\u003e\n\n\u003cp\u003e\u003ca href=\"/rnn13\"\u003e点击这里使用\u003c/a\u003e\u003c/p\u003e","tags":["机器学习","JavaScript","独人13"],"title":"AI生成《创人药》","uri":"https://chaosinism.github.io/posts/ai-duren13/","year":"2019"},{"content":"Ludum Dare是一项游戏制作赛事，参赛者需要在48小时内独立完成一款游戏的制作，游戏用到的绝大多数素材也需要参赛者自制。每届赛事会指定参赛游戏的主题，本次比赛为第45届，主题是“Start with nothing”。\n我参赛的原因是近期在考察开源游戏引擎Godot Engine，虽然看了一些文档，但还没有实践过。Ludum Dare的举办时间经常和我其他的安排冲突，但这一次碰巧能抽出空来，因此是一次锻炼的好机会。\n作品简介   规则与操作说明\n  本作是一个即时制的拼字游戏，玩家在游戏开始时拥有“NOTHING”这7个字母，可以在屏幕中四处移动来收集新的字母拼上去，游戏目标是将一开始的7个字母转化为7个完整的单词。屏幕中存在一些特殊颜色的字母，会带来奖励分数或是损害玩家的生命值，生命值归零也会使游戏结束。游戏得分由拼词速度、单词长度、剩余生命值等多个因素决定。\n游戏的背景大概是想表示人出生时一无所有，但可以自己选择追求的目标。每拼出一个单词代表人生进入下一个阶段，随着主角年龄的增长，游戏难度也会提高（字母速度加快、伤害增多等）。\n游戏地址和源码提供如下：\n 参赛页面\n 游戏本体\n 源代码\n  制作流程 机制 题目公开之后首先直接睡觉，没问题的。躺在床上思考了一下决定把拼字作为游戏机制，主要考虑到用文字把比赛主题明白写出来肯定就不会跑题，并且文字游戏需要的美工也比较少。之后就是确定一些细节来提高可玩性，比如多种不同的得分项目，以及根据游戏进程提高难度。虽说如此，并没有时间来验证这些设定的平衡性。\n美术 平时都在做一些重口味的东西，但这个比赛大概不太欢迎这种题材，所以转而把风格搞得清新一点。\n  游戏美术\n  首先要画背景，因为是拼字游戏，所以采用类似羊皮纸的材质。比赛不允许使用现成的素材，但是用TextureGenerator这个工具可以达到类似的效果。\n之后UI用MediBang Paint的叶子形状笔刷随便划几下。\n主角各年龄的形象仍然用MediBang Paint画，为了快速完成就找了一些矢量图做参考，说实话已经接近描图了，不过这个在比赛中算作“派生素材”（Derivative Works），在规则允许的范围内。\n之后把这些图都塞进工程文件夹即可，Godot会自动导入并处理它们的。\n音乐   敷衍了事的音乐\n  我注意到很多独立游戏作者对于设计、编程、美术等都能自行包办，但音乐经常外包出去。这个比赛的参赛者也不例外，很多人没做音乐，或是用到自动生成器（如Abundant Music，这个项目之后可以考察一下）。既然如此，自制音乐可能算是个优势。我也不打算下太大力气，采用的方法是把电子琴接入LMMS然后即兴弹了一些东西，旋律可能比较平庸，并且没头没尾的。\n我试图制作一种动态的混音——随着游戏进行，即主角“年龄”的增加，减弱高音成分同时增大低音成分。结果是效果不好，同时要打包的音频资源体积增大到三倍。虽然不成功，但不是致命失误，所以懒得改了。\n编程   树状结构\n  Godot的特色是将每个游戏元素都作为一个“节点”，可以用一套相同的方法来操作它们。将节点安排为树的结构就可以搭建出游戏场景，在这种数据结构下，也很容易由一个节点查找到另一个节点来进行调用。\n  Godot界面\n  Godot提供图形编辑器来定义、组织节点。可以为每个节点编制脚本，这里使用的脚本语言是引擎自创的GDScript，语法与Python非常类似，很容易上手。编程主要是定义以下几项：节点出现时的行为、每一帧的行为和遇到事件时的反应。引擎提供很多内建的函数，比如物体之间的碰撞检测，所以大多情况下只需专注于游戏逻辑的编写。具体到这个游戏，代码只有300多行。\n总结 总结一下的话，游戏制作过程的时间分配是这样的：\n 机制：?小时（基本是睡觉的时候想的） 美术：2小时（包含UI布局配色、背景与Sprite的绘制） 音乐：1小时（1首约2分钟、3个乐器轨的BGM，2个音效） 编程：7小时（包括写代码与测试游戏，大部分时间在查文档）  两个晚上都正常睡了觉，做完这些之后还剩个大半天。不过目的已经达到了，本来也不是为了争胜负，所以就到此为止了。\n比赛的评定采取参赛者互相打分的模式，我体验了其他参赛者的一些游戏，同时也收到不少反馈。在此可以总结出游戏的一些不足：\n 有些玩家忽视了可以丢弃掉当前收集的字母，并且收集字母过多的情况下可能会出现BUG，应该设置一个上限，并在达到上限时弹出操作提示。 拼出的单词并非总是有意义，解决这个问题需要考虑词频之类的要素，在比赛期间内是很难解决了。 前面谈到的混音问题，有一些参赛作品采用了类似的方式，但效果比我好。可能思路行得通、执行不到位。  至于收获，就是目前为止对Godot的体验确实很不错，基于节点与脚本语言的创作思路很符合我的习惯，与其他开源图像、音频工具也配合良好。不过在大型项目以及性能优化方面的表现我还没有考察过。之后有时间可能会继续使用它做一些别的东西，也可能会进行一些游戏引擎之间的比较。\n","id":7,"section":"posts","summary":"\u003cp\u003eLudum Dare是一项游戏制作赛事，参赛者需要在48小时内独立完成一款游戏的制作，游戏用到的绝大多数素材也需要参赛者自制。每届赛事会指定参赛游戏的主题，本次比赛为第45届，主题是“Start with nothing”。\u003c/p\u003e\n\n\u003cp\u003e我参赛的原因是近期在考察开源游戏引擎\u003ca href=\"https://godotengine.org/\"\u003eGodot Engine\u003c/a\u003e，虽然看了一些文档，但还没有实践过。Ludum Dare的举办时间经常和我其他的安排冲突，但这一次碰巧能抽出空来，因此是一次锻炼的好机会。\u003c/p\u003e","tags":["Godot","LMMS","独立游戏"],"title":"Ludum Dare 45参赛体验\u0026作品","uri":"https://chaosinism.github.io/posts/ld45/","year":"2019"},{"content":"我以《东方Project》的新作角色“杖刀偶磨弓”为主角制作视频《┗|∵|┓磨弓的偶像宣言》（Bilibili, Niconico），过程中也制作了该角色的3D模型，所以用MMD格式发布出来。可在BowlRoll下载，另外也收录在了本博客的汇总页面。以下对模型内容、用到的制作和渲染方法等做一些介绍。\n模型内容   模型预览\n   压缩包内包括以下模型文件：\n   文件 说明     mayumi_armor.pmx 原作风格的角色模型。   mayumi_dress.pmx 将盔甲换为裙子，适合舞蹈视频。   sword.pmx 角色手持的武器。   haniwa.pmx 角色的埴轮弹幕。    另外，盔甲有一个法线贴图（tex/DressNormal.png）。MMD本身不支持法线贴图，但如果有相应的MME就可以利用。\n制作过程 之前制作MMD模型我经常使用たむたむす〜る，这其实是TEATIME系列游戏内置的编辑器。由于使用方便，不少MMD作者用它来做模型，这样做出的模型发布时一般会标注“たむたむ式”。虽然是用于同人创作，TEATIME毕竟是商业游戏，感觉并不是特别正当的手段，所以这次尝试换一种方法，采用VRoid+Blender。\n  VRoid（左）与完成品（右）\n   VRoid是Pixiv出品的建模软件，主要用于制作卡通风格的人物，它不仅免费，并且向制作者开放了大部分授权，作品用于VR游戏、虚拟主播、3D动画都是可以的。VRoid最强的功能是制作发型，可以直接用鼠标画出头发，但它对于服装或是小物件的建模就不是很方便了。因此这里只调整完素体和头发就进行导出（上图左）。\nVRoid的输出格式是vrm，它其实可以作为glb文件导入到其他3D软件中，另外也有人制作了专门的工具VRM2PMXConverter将其转换为MMD使用的pmx文件。\n之后用Blender制作服装和装饰物，再用GIMP画贴图，模型就完成了（上图右），用Blender_mmd_tools将它导出为pmx格式。\n渲染技巧 虽说发布的是MMD模型，我自己在做视频的过程中其实几乎没有用到MMD，都是在Blender中进行渲染，因为视频需要用到粒子特效、布料解算以及几种不同的Shading，在MMD中不方便。Shading用到下面几种，都是较为常规的方法。\n边缘光   边缘光效果\n   动画的舞台设置在《东方鬼形兽》原作的畜生界，是一个充满灯光的场景，因此加入一个边缘光的效果。判断模型的边缘通常是用法线计算菲涅耳公式，Blender中有现成的节点，设置如下。\n  Shader节点设置\n  \n卡通渲染   卡通渲染效果（右图为原作——CHiCO with HoneyWorks，《我的偶像宣言》）\n   本视频是对手书的仿制，实际上一部分内容也是手绘的，为了将3D与手绘结合起来需要使用卡通渲染。原作使用偏蓝色的纯色阴影，这里也模仿这种效果，节点设置如下。另外，角色头发与眼睛的阴影是画在贴图里的，所以也要换成另外的纯色为主的贴图。\n  Shader节点设置\n   设置完成后再使用Freestyle功能进行描边，虽然和手绘还是有较大的差距，但风格上至少可以在一定程度上统一了。\n","id":8,"section":"posts","summary":"\u003cp\u003e我以《东方Project》的新作角色“杖刀偶磨弓”为主角制作视频《┗|∵|┓磨弓的偶像宣言》（\u003ca href=\"https://www.bilibili.com/video/av68600342/\"\u003eBilibili\u003c/a\u003e, \u003ca href=\"https://www.nicovideo.jp/watch/sm35721224\"\u003eNiconico\u003c/a\u003e），过程中也制作了该角色的3D模型，所以用MMD格式发布出来。可在\u003ca href=\"https://bowlroll.net/file/207898\"\u003eBowlRoll\u003c/a\u003e下载，另外也收录在了本博客的汇总页面。以下对模型内容、用到的制作和渲染方法等做一些介绍。\u003c/p\u003e","tags":["MMD","VRoid","Blender","东方Project"],"title":"杖刀偶磨弓 - 模型配布/说明","uri":"https://chaosinism.github.io/posts/mmd-mayumi/","year":"2019"},{"content":"这个博客差不多成型了，于是总结一下搭建个人主页的过程中使用的工具以及使用体验等等。\n网页托管 - GitHub Pages 建立博客有两个选项，既可以在现成的博客平台上注册，也可以自己搭建。前者当然要简单快捷得多，但也有几个明显的缺点，比如说注册可能需要实名制，内容必须接受平台的审查，以及文章的导出、备份和转移都未必方便。因此我选择手动搭建博客，也顺带着了解一些新技能。\n既然要自己搭建博客，第一步是要寻找一个服务器来储存自己的网页。考虑到我经常在文章中引用GitHub上的项目，页面就也顺便放在了GitHub Pages上。这是GitHub提供的免费、不限流量的网页托管服务，支持静态页面。使用也比较方便，像通常的Git仓库那样更新文件就可以。访问方面，目前国内在大多数情况下是没问题的，不知道今后会怎样。不过如果某一天不能访问了，把内容都搬到另一个地方就行了，这也是自己搭建博客的优点之一。\n静态页面生成 - Hugo GitHub Pages仅支持展示静态页面，因此用WordPress制作的动态网站是没法托管在上面的。我的选择是用Hugo生成静态页面。这也是一个比较方便的工具，不需要自己写代码，一个命令就可以由文章直接生成网站，速度也非常快。\nHugo支持数量非常多的主题或模板，适用于各种类型的网站。我暂时未考虑外观的问题，所以选了一个看起来较简洁的主题Mainroad，之后可能还会换。\n文章编辑 - Typora 如果想在文章中自定义格式或是插入图片、链接等，需要使用Markdown语言。虽然Markdown语法非常简单，不过我之前并没怎么使用过，所以又专门找了一个编辑器，Typora。它能够即时地将写下的格式语法渲染出来供作者预览。使用之后感觉这个工具非常方便，比如说从网页上复制下来的内容会被自动转换格式，图片也都保留，另外也提供了专注模式、字数统计和显示大纲等功能，用来做笔记或写作都是很合适的（虽然我不怎么写作）。\n流量统计 - Google Analytics 静态页面的最大缺点就是不能支持各类应用，所以生成出来的网站并不自带流量统计和评论功能。但这些功能又是十分必要的，因此只能选择第三方的服务。虽然这个博客的流量估计用手就能数出来，我还是决定放一个正式的统计功能上去。我目前使用Google Analytics，国内意外地可以正常访问的样子。使用方法不需多说，只要注册然后手动插入一行代码到页面里就够了。\n评论系统 - Staticman 评论功能是目前最大的问题。Hugo最推荐的第三方服务是Disqus，类似的评论托管平台也有不止一个，但是它们大多无法在国内访问，这一点倒并不意外。对于Github这样的代码仓库，有人想出一些其他的方法来实现评论功能。其一是Staticman，一旦有访客提交评论，它会帮忙把评论上传到仓库。这个服务都是个人在无偿运行，并不太稳定，不过即使出现故障，也只是提交评论的API不能使用，现有的评论是保存在自己手里的。另外还有Utterances，把Github的issue功能改造成了评论区，当然这要求访客也得有Github账号才行。\n我现在尝试的是Staticman，由于这是一个较为小众的解决方案，似乎逃不过自己写代码。我不懂相关的语法，只能参照资料，边猜意思编写，现在大概至少基本功能是有了。需要感谢这几篇文章（1,2,3）的作者才行。\n目前评论功能需要我审核才会显示在网页上，这是因为听说过这样的例子——有人故意自己发恶意内容在别人网站里，然后污蔑这个人开色情网站。不知道现在还有没有这种人，但我决定先小心点。此外，即使网页上看不到，评论其实已经立刻更新在GitHub仓库中了，是公开的，所以我并没有任何控评的意思。这个评论系统确实不是特别方便，以后可能会考虑更换方案，不过反正根本没什么人留言，完善评论区并不是一个紧急任务，真要找我也可以通过这个博客中记载的其他联系方式。\n","id":9,"section":"posts","summary":"\u003cp\u003e这个博客差不多成型了，于是总结一下搭建个人主页的过程中使用的工具以及使用体验等等。\u003c/p\u003e","tags":[],"title":"搭建个人主页的心得","uri":"https://chaosinism.github.io/posts/blog-setup/","year":"2019"},{"content":"若想由一段音频素材（如一首歌或一段对话）制作出供人力Vocaloid使用的音源，第一步是要在素材中把可以用的发音逐个截取出来，此过程通常较为枯燥费力。因此，本文尝试探索一种结合AI语音识别技术加速该过程的方法。下面介绍一下步骤与工具。\n需注意，本文原始发布时间较早，仅对此问题进行了初步的探索，并未得到一个成熟的解决方案，效果远非理想。另外，目前没有很方便的图形界面来实现文中所述功能，因此建议在对命令行与Python有一定使用经验的前提下阅读。\n（原始投稿地址：https://www.bilibili.com/read/cv465184 ）\n  目标：自动得到一系列单音节发音的wav文件\n  \nWatson Speech to Text 的使用方法 本步骤使用IBM的语音识别应用来获得每个单词在音频中的位置（起始时间与终止时间），以便之后的截取。\n在这个网址注册IBM账号并申请该应用：https://www.ibm.com/watson/services/speech-to-text/\n  点击左侧按钮即可注册\n   注册成功后，目前可获得每月100分钟的免费额度，并得到用户名与密码。与注册时输入的用户名密码不同，它们是专门用于语音识别服务的。\n  点击“显示”可看到用户名和密码\n   IBM提供一系列API来调用语音识别应用，其中通过HTTP是比较便捷的一种方法。如果是Linux等系统，可以在命令行中使用如下形式的curl命令；如果是Windows系统，可能需要先下载curl（https://curl.haxx.se）：\ncurl -X POST -u \u0026quot;你的用户名\u0026quot;:\u0026quot;你的密码\u0026quot; --header \u0026quot;Content-Type: audio/wav\u0026quot; --data-binary \u0026quot;@你的音频素材文件.wav\u0026quot; \u0026quot;https://stream.watsonplatform.net/speech-to-text/api/v1/recognize?model=zh-CN_BroadbandModel\u0026amp;word_confidence=true\u0026amp;timestamps=true\u0026quot; --output curl_result.json  介绍一下涉及到的选项：\n Content-Type: audio/wav： 指明文件类型，最好使用单通道的wav文件，另外对采样率也有要求，下面会解释。 model=zh-CN_BroadbandModel：指明语言是中文，这里Broadband对应16000Hz采样率，另有Narrowband对应8000Hz采样率。除中文外，也支持识别其他语言，如日语可以用ja-JP_BroadbandModel，英式英语en-GB_BroadbandModel，美式英语en-US_BroadbandModel等。 word_confidence=true：AI对识别出的每个单词有一个置信度（0~1），越接近1表明识别越准确。 timestamps=true：每个单词在音频中的起始与终止秒数，这是我们最需要的数据。  若不出意外，等待几分钟后会有一个curl_result.json文件被下载，其中就是语音所对应的文字，与我们需要的时间数据。\n提取JSON文件的数据并进行音频分割 得到json文件后，就可以按照里面提供的时间信息来切割原本的音频素材。我写了一个简单的Python脚本来执行这个操作，在这里分享一下:\n https://github.com/Chaosinism/utau_tools  将代码中的文件名换成对应的wav与json文件，执行就可以得到分割后的多个发音。\n脚本主要用到这些库：\n json： 用于读取json格式的数据。 wave：用于读取并操作wav文件。 scipy：著名的科学计算工具，此处用于辅助操作wav文件。 pypinyin：将汉字转换为拼音，用于为切割后的文件命名。  此脚本仅能用于中文音频，但其他语言也大同小异，稍作修改即可。默认情况下脚本输出全部被识别出的发音，其中一些可能并不正确或不适合作为音源，可以设置confidence_threshold变量以仅仅输出置信度较高的发音。\n注意事项  获得发音文件仅是音源制作的第一步，需要后续手动调整来提高音源质量。以UTAU为例，oto.in并不会自动生成，需要在UTAU中手动设置，或使用setParam来辅助设置。 请勿将本文中介绍的方法用于非法用途。  结论与反思 此次尝试较为肤浅，效果也有限，经简单测试，提取出的发音只有不到一半可用。目前各大厂商提供的语音识别模型有很大比重是对语义的判断，而从制作音源的角度来看，仅需要对单个发音的识别，词句级别的识别与上下文都是不必要的，所以也许反而应该使用更原始的模型。我也尝试使用可自行定制的离线语音识别系统，如CMU Sphinx，但效果更差。若有改进建议或是其它想法，欢迎交流讨论。\n","id":10,"section":"posts","summary":"\u003cp\u003e若想由一段音频素材（如一首歌或一段对话）制作出供人力Vocaloid使用的音源，第一步是要在素材中把可以用的发音逐个截取出来，此过程通常较为枯燥费力。因此，本文尝试探索一种结合AI语音识别技术加速该过程的方法。下面介绍一下步骤与工具。\u003c/p\u003e\n\n\u003cp\u003e需注意，本文原始发布时间较早，仅对此问题进行了初步的探索，并未得到一个成熟的解决方案，效果远非理想。另外，目前没有很方便的图形界面来实现文中所述功能，因此建议在对命令行与Python有一定使用经验的前提下阅读。\u003c/p\u003e\n\n\u003cp\u003e（原始投稿地址：\u003ca href=\"https://www.bilibili.com/read/cv465184\"\u003ehttps://www.bilibili.com/read/cv465184\u003c/a\u003e ）\u003c/p\u003e","tags":["UTAU","机器学习","Python"],"title":"利用语音识别技术辅助制作音源的初步尝试","uri":"https://chaosinism.github.io/posts/voice-extraction/","year":"2019"},{"content":"本文探讨MMD与Kinect v2设备不兼容的问题。文章以总结整理网络上的资料与开源项目为主，结合少量的原创工作，最终提出一种解决方案。由于我对这一领域只有初步的了解，若发现文章中有不准确或失去时效性的内容，欢迎批评指正。\n（原始投稿地址：https://www.bilibili.com/read/cv1750314 ）\n问题描述 Kinect是微软开发的动作捕捉设备，最初用于Xbox 360与Xbox One。尽管已经停产的Kinect可能不是一款成功的游戏外设，对于业余3D动画作者来说，它提供了一种低成本的动作捕捉方法，多种3D动画软件均存在Kinect的插件。\n  Kinect(左)与Kinect v2(右)\n   MMD内置的动作捕捉功能同样基于Kinect硬件。然而，用于Windows的Kinect共有两代产品，MMD只支持其中的初代，而不支持第二代——Kinect v2。如果新用户希望购置一台设备用于MMD动画的动作捕捉，那么自然是推荐购买Kinect初代。然而也有用户已经拥有Kinect v2，并希望将其用于MMD。因此，本文接下来将介绍此设备不被兼容的原因，并探讨解决这一问题的方法。\n问题分析 MMD的动作捕捉功能依赖于以下几个组件——OpenNI，Nite与DxOpenNI.dll。它们的功能以及采集动作的流程如下：\n OpenNI：从Kinect摄像头中提取颜色、深度等图像信息。 Nite：由图像信息推导出被采集者身体各部位的空间位置。 DxOpenNI.dll：MMD插件，将身体部位的坐标传给MMD，转化为骨骼运动。  OpenNI与Nite支持数种传感器硬件，其中包含初代Kinect，但不包含v2。因此要想增加MMD对Kinect v2的兼容性，必须做到以下几点——替换OpenNI与Nite，并修改DxOpenNI.dll。\nOpenNI的替代品首选微软官方的Kinect SDK 2.0，事实上已有N站UP主发布了基于Kinect SDK的新DLL（ https://www.nicovideo.jp/watch/sm26054087 ）。然而它在捕捉躯干与腿部运动时均有较大的缺陷，可用性并不高。据我所知该bug至今未被修复，我尝试修改代码也未果，因此本文暂且不考虑使用Kinect SDK。\n另一方法是采用这些组件的后继版本，OpenNI 2与Nite 2。虽然它们默认不支持Kinect v2，但有人编写了新驱动使它们能够顺利操控该设备。下面的章节介绍这种方法。\n解决方案 首先，安装OpenNI 2与Nite 2，并编写能够调用它们的新DxOpenNI.dll。这部分工作已有人完成，作者为Heresy，他写了以下文章来介绍：\nhttps://kheresy.wordpress.com/2013/03/07/dxopenni-for-openni-2/\n操作步骤在该文章中已经被描述得很详细，本文不再重复。但文章中的下载链接有一些已经失效，这里补充一些各组件的下载地址。\nOpenNI 2：https://structure.io/openni ，下载Windows (x86)版。\nNite 2：https://drive.google.com/file/d/0B3e4_6C5_YOjQWtCcVl3VnRsWG8/\n上面的地址可能不在墙内，另有一个百度盘（ http://pan.baidu.com/s/1gd9XdIV ）也提供这两个组件，注意选择系统是Windows (x86)、版本号为2开头的文件来下载。\nDxOpenNI.dll：https://bowlroll.net/file/185452 ，在文件夹“DxOpenNI2_by_Heresy”中。\n按照Heresy的文章将以上组件都安装好后，要另为OpenNI 2准备驱动。这里需要使用的驱动是libfreenect2（ https://github.com/OpenKinect/libfreenect2 ）。\n首先在https://github.com/daynix/UsbDk/releases 下载并安装UsbDk_1.0.19_x64.msi。\n然后是libfreenect2本体，这里要注意，MMD是32位软件，所以libfreenect2和OpenNI 2、Nite 2同样，必须采用32位版本，作者没有提供，我自己编译了一下（编译的环境是Visual Studio 2013，可能会需要相应的Visual C++ Redistributable Packages）。编译后的文件位于之前的zip包里（ https://bowlroll.net/file/185452 ）的文件夹“Driver”。如果顺利完成了前面的步骤，现在MMD目录下应该有一个“OpenNI2”文件夹，将编译后的文件均复制到“OpenNI2\\Drivers”即可。\n若以上操作均成功，MMD将可以使用Kinect v2进行动作捕捉。\n补充说明 附录1：libfreenect2的编译 似乎libfreenect2是推荐用户自己进行编译的，因此我也不确定我编译的版本是否所有人都能使用。Github中虽然有详尽的编译步骤，但都没有考虑到32位的情况。我根据自己的体验总结了以下几个注意事项，如果有人想自行编译，可作参考：\n 请使用Visual Studio 2012或2013，因为之后的版本只能编译64位（这个似乎是CUDA的问题）。\n “Build libusb”步骤中的CMD文件需要修改，13行Platform的值改成x86，18~20行x64改Win32。\n TurboJPEG和GLFW都安装32位版，但是文件夹仍按照步骤里的指示来命名。\n 最后编译的命令（cmake .. -G \u0026ldquo;Visual Studio 12 2013 Win64\u0026rdquo;）省略掉Win64字样。\n  附录2：减少抖动 按以上方法进行动作捕捉时，有时会感觉模型的骨骼一直在抖动，针对这一点有以下几个改善方法：\n 我稍微修改了DxOpenNI.dll加入平滑功能，新文件位于之前的zip包里（ https://bowlroll.net/file/185452 ）的文件夹“DxOpenNI2_Modified”，可以考虑采取这个版本来减少抖动。这里我的编译环境换成了Visual Studio 2017。（2013无法成功编译，原因尚不明。） 捕捉开始时，可以做出易于识别的姿势，方便机器对人体进行更好的定位，比如下面这个“PSI Pose”。 使用VMD Reduction Tool（ https://sites.google.com/site/moggproject/enghome ）。    PSI Pose\n  \n","id":11,"section":"posts","summary":"\u003cp\u003e本文探讨MMD与Kinect v2设备不兼容的问题。文章以总结整理网络上的资料与开源项目为主，结合少量的原创工作，最终提出一种解决方案。由于我对这一领域只有初步的了解，若发现文章中有不准确或失去时效性的内容，欢迎批评指正。\u003c/p\u003e\n\n\u003cp\u003e（原始投稿地址：\u003ca href=\"https://www.bilibili.com/read/cv1750314\"\u003ehttps://www.bilibili.com/read/cv1750314\u003c/a\u003e ）\u003c/p\u003e","tags":["MMD","Kinect","驱动","C++"],"title":"Kinect v2与MMD动作捕捉","uri":"https://chaosinism.github.io/posts/kinect-mmd/","year":"2019"},{"content":"自制的Vegas脚本，用于MIDI可视化。\n（原始投稿地址：https://www.bilibili.com/read/cv1027442 ）\n基本信息  脚本功能：以自定义图案为音符，画出MIDI文件的五线谱。 源码地址：https://github.com/Chaosinism/vegas_scripts 下载地址：https://github.com/Chaosinism/vegas_scripts/releases 适用环境：Windows, Sony Vegas Pro 13以上  动机与背景   使用效果\n   在视频【组曲】芳文社Mashup中，我模仿Youtube上的视频作者grantwoolard制作画面效果。他的特色是使用音乐家的头像画出音频的五线谱。\n  Classical Music Mashup, by grantwoolard\n   我没有查到他是如何制作的，于是自己写了一个Vegas脚本，可以根据MIDI文件和自定义的图像文件来制造出这种效果。\n使用说明 以下陈述脚本的安装与使用方法。\n安装方法  在 https://github.com/Chaosinism/vegas_scripts/releases 下载脚本，Vegas 13的用户请下载staff_visualizer_vegas13.zip，Vegas 14、15和16的用户请下载staff_visualizer_vegas1415.zip。 下载zip文件后解压，确保DLL/NAudio.dll未处于锁定状态。否则，在右键-【属性】中点击【解除锁定】。    解除DLL文件锁定\n   - 将所有文件拷贝至C:\\Program Files\\Sony\\Vegas Pro XX\\Script Menu，其中“XX”为Vegas版本号，如“13.0”、“14.0”等。\n使用方法  使用Vegas菜单中的【工具】-【脚本化】-【staff_visualizer】来启动脚本。 按对话框提示，选择一个MIDI文件，与一个作为音符的图像文件（图片和视频皆可，只要是Vegas支持的格式）。    脚本所需的输入\n   - 在新对话框中调整选项。例如，如果要在下图中红色区域插入五线谱，则各参数的意义如图所示。\n     选项示意图\n   - 点击完成，Vegas将自动生成数个视频轨道，效果如图。\n  输出示意图（屏幕）\n     输出示意图（轨道）\n  \n参考与致谢  https://github.com/evankale/VegasScripts https://github.com/naudio/NAudio ","id":12,"section":"posts","summary":"\u003cp\u003e自制的Vegas脚本，用于MIDI可视化。\u003c/p\u003e\n\n\u003cp\u003e（原始投稿地址：\u003ca href=\"https://www.bilibili.com/read/cv1027442\"\u003ehttps://www.bilibili.com/read/cv1027442\u003c/a\u003e ）\u003c/p\u003e","tags":["Vegas","C Sharp","软件脚本","MIDI"],"title":"MIDI五线谱可视化——自制Vegas脚本","uri":"https://chaosinism.github.io/posts/script-score/","year":"2019"},{"content":"自制的用于辅助鬼畜/音MAD制作的Vegas脚本，在此做一下介绍。\n（原始投稿地址：https://www.bilibili.com/read/cv392013 ）\n发布信息  脚本名称：音MAD助手\n 源码地址：https://github.com/Chaosinism/vegas_scripts\n 下载地址：https://github.com/Chaosinism/vegas_scripts/releases\n 适用环境：Windows, Sony Vegas Pro 13以上版本\n  功能介绍   使用效果\n   - 国人制作鬼畜与音MAD视频通常混合使用FL等DAW与Vegas等非线编软件，而两者工程文件无法互通，导致额外的工作量。此脚本意在加强Vegas对MIDI文件的处理能力，减少软件切换带来的成本。 - 脚本接受MIDI文件与视频/音频素材作为输入，自动生成剪切、调音完毕的视频与音频轨道。\n安装步骤  由于Vegas提供的API功能有限，目前此脚本的安装过程较为繁琐。共有以下步骤： 下载zip文件后解压，确保DLL/NAudio.dll未处于锁定状态。否则，在右键-【属性】中点击【解除锁定】。    解除DLL文件锁定\n   - 将所有文件拷贝至C:\\Program Files\\Sony\\Vegas Pro XX\\Script Menu，其中“XX”为Vegas版本号，如“12.0”、“13.0”等。\n  将脚本放入Vegas安装目录\n   - 在Vegas中任意插入一个音频文件，右键添加音频FX，在弹出的窗口中找到插件“移调（Pitch Shift）”，如果Vegas并非英文版，则右键将插件名称修改为“Pitch Shift”。（否则脚本可能无法识别该插件）\n  找到移调插件\n   - 添加该插件，按图片进行设置，并将设置保存为预设。之后将图中的“3”改为其他数字，保存另一个预设。共需保存25种预设（数字由“-12”至“12”）。\n    此步骤须手动完成\n   - 重启Vegas。 - 至此，可以使用Vegas菜单中的【工具】-【脚本化】-【otomad_helper】来启动脚本，并按照提示操作生成音频、视频轨道。\n常见问题 （原始投稿地址：https://www.bilibili.com/read/cv495305 ）\n自该脚本发布以来，我陆续收到一些使用反馈。我很高兴看到脚本确实地发挥了一些辅助作用，但同时也意识到许多用户无法顺利地运行脚本。一方面，我并非专业程序员，能力有限，开发、测试环境也不完善；另一方面，Vegas提供的接口和文档实在不能称为充足，造成的结果就是，现阶段脚本的健壮性确实比较差，出现差错难以自动排查、修复。所幸脚本出错时Vegas会显示一些错误信息（通过在报错窗口中点击“详细信息”查看），在此非常感谢多位用户的耐心试用与交流，让我能收集到这些错误信息，并尝试提供一些解决方法。\n1. 错误类型: Vegas版本不符 报错时机：在菜单运行脚本时\n错误信息：\n  解决方法：使用与Vegas版本对应的脚本\n补充说明：Vegas 13与Vegas 14/15/16所对应的脚本是有一些不同的，我在Github的release里分别放出了两个下载链接，请使用正确的版本。具体来说，Vegas系列软件自14起被索尼出售给了MAGIX，所以一些库的命名也变化了，不再含有“Sony”字样。\n2. 错误类型：找不到NAudio.dll 报错时机：在菜单运行脚本时\n错误信息：\n  解决方法：确保将NAudio.dll放置到正确的位置；确保此文件已被解除保护\n补充说明：可见安装方法中的说明。NAudio是一个用于处理音频文件的库（https://github.com/naudio/NAudio），我调用它来读取MIDI文件，因此NAudio.dll这个文件是必不可少的。\n3. 错误类型：无法读取MIDI文件 报错时机：读取MIDI文件后 或 生成音频\\视频途中\n错误信息：（可能有多种信息）\n    解决方法：用宿主软件导入该MIDI，然后重新输出一个新的MIDI文件\n补充说明：MIDI文件有多种格式，脚本不保证都能够正确读取。所幸主流宿主软件在默认设置下导出的MIDI文件一般是可以读取的。（目前测试过FL Studio, LMMS与Music Studio for iPad均可兼容）\n4. 错误类型：无法调用移调插件 报错时机：生成音频\\视频途中\n错误信息：\n  解决方法：确保你的Vegas含有“移调”插件，并且名称已改为“Pitch Shift”\n补充说明：具体可见安装方法的说明。如果仍然不能解决，另一种方式是找到脚本中的所有的\nvegas.AudioFX.FindChildByName(\u0026quot;Pitch Shift\u0026quot;)  字样（一共4处），并将它替换为\nvegas.AudioFX.FindChildByUniqueID(\u0026quot;{ED1B4100-93BE-11D0-AEBC-00A0C9053912}\u0026quot;)  5. 错误类型：无法调用移调插件的预设效果 报错时机：生成音频\\视频途中\n错误信息：\n  解决方法：确保在移调插件中手动添加了所有的25个预设，且命名正确\n补充说明：具体可见安装方法的说明。这25个预设是上下一个八度以内的所有变调种类，缺少任何一个都有可能出错。手动添加预设的确非常麻烦，但Vegas无法使用脚本来指定变调的具体参数，因此只好绕这个弯子。\n6. 错误类型：无法读取媒体流 报错时机：生成音频\\视频途中\n错误信息：\n  解决方法：在设置界面，纯音频素材不要勾选“包含视频”；纯视频素材不要勾选“包含音频”\n补充说明：若仍不能解决，说明该素材文件可能是Vegas不支持的格式，可以手动把该文件拖入Vegas中看一下是否视频音频都正常。\n参考与致谢  https://github.com/evankale/VegasScripts https://github.com/naudio/NAudio ","id":13,"section":"posts","summary":"\u003cp\u003e自制的用于辅助鬼畜/音MAD制作的Vegas脚本，在此做一下介绍。\u003c/p\u003e\n\n\u003cp\u003e（原始投稿地址：\u003ca href=\"https://www.bilibili.com/read/cv392013\"\u003ehttps://www.bilibili.com/read/cv392013\u003c/a\u003e ）\u003c/p\u003e","tags":["Vegas","音MAD","C Sharp","软件脚本","MIDI"],"title":"音MAD助手——自制Vegas脚本","uri":"https://chaosinism.github.io/posts/script-otomad/","year":"2019"},{"content":" 本页面列举笔者自制资源，包含MMD模型、软件脚本、工程文件等。 依据资源性质，资源的使用与传播须遵循不同的协议，详情请参照每一项资源链接中的说明。  MikuMikuDance(MMD)模型    更新日期 名称 原作 示意图 原始配布地址 下载地址 备注     2017-12 津岛善子 LoveLive! Sunshine!!  Bilibili BowlRoll たむたむ式   2017-12 苗寨木制门 取材自现实  Bilibili BowlRoll    2018-03 高海千歌\n樱内梨子\n渡边曜 LoveLive! Sunshine!!  Bilibili BowlRoll たむたむ式 / 服装未还原   2018-09 大场奈奈 少女歌剧  Bilibili BowlRoll たむたむ式 / 校服   2018-11 独人13 取材自现实  Bilibili BowlRoll    2019-01 うちっちー\n米歇尔 取材自现实\nBanG Dream!  Bilibili BowlRoll 同时提供Blender源文件   2019-07 牛崎润美 东方Project  Bilibili BowlRoll たむたむ式   2019-09 杖刀偶磨弓 东方Project  Bilibili\nNiconico BowlRoll VRoid式\n说明   2020-02 刁蛮 取材自现实  Bilibili BowlRoll たむたむ式    软件脚本    更新日期 名称 适用软件 源码地址 使用方法     2018-04 音MAD助手 Vegas Pro Github 站内链接   2018-08 MIDI五线谱可视化 Vegas Pro Github 站内链接    自制工具    更新日期 名称 源码地址 使用方法     2020-02 音源分割工具 Github 站内链接1\n站内链接2   2020-02 Bilibili评论统计工具 Github 站内链接    工程文件    更新日期 名称 适用软件 原始作品地址 下载地址 备注     2017-10 露比☆大冒险 PowerPoint Bilibili BowlRoll 《LoveLive! Sunshine!!》同人动画   ","id":14,"section":"posts","summary":"\u003cul\u003e\n\u003cli\u003e本页面列举笔者自制资源，包含MMD模型、软件脚本、工程文件等。\u003c/li\u003e\n\u003cli\u003e依据资源性质，资源的使用与传播须遵循不同的协议，详情请参照每一项资源链接中的说明。\u003c/li\u003e\n\u003c/ul\u003e","tags":["资源汇总"],"title":"自制资源汇总","uri":"https://chaosinism.github.io/posts/homemade/","year":"2019"},{"content":" 本页面搜集整理网络上可用于多媒体制作的免费资源，自身并不提供资源的下载。 部分条目使用粗体标记，表示笔者自身使用该工具/服务的频率较高，是完全主关的评价。本站其他文章也可能会更频繁地涉及到它们。 被列举的网站除免费资源外，可能也提供收费资源。此外，资源的使用遵循不同种类的协议，需要使用者自行鉴别。 本页面将不定期更新，移除失效链接。部分网站可能有访问区域限制，笔者没有精力逐一验证并注明，还请见谅。     网站 领域 资源种类 简介     artstation.com 绘画 \\ 3D 作品 \\ 教程 \\ 素材 内容多为美术从业者提供，包括高质量的作品与教程。   pixiv.com 绘画 作品 \\ 教程 不多谈。   deviantart.com 绘画 \\ 3D 作品 \\ 教程 \\ 素材 功能类似Pixiv的英文社区。注意其中可能存在一些盗用的资源。   80.lv 绘画 \\ 3D 作品 \\ 教程 涵盖动画、游戏美术、视频特效等多个领域，其中对从业者的深度采访较有价值。   behance.com 设计 作品 有名的设计展示平台。   freebiesbug.com 设计 作品 \\ 素材 平面设计字体、源文件。   huaban.com 设计 作品 \\ 素材 国内的设计网站，还有人上传游戏和动画的设定集之类的东西。   zcool.com.cn 设计 作品 \\ 素材 国内的设计网站。   3dmdb.com 3D 素材 3D模型搜索引擎。   free3d.com 3D 素材 免费3D模型搜索与下载。   sketchfab.com 3D 作品 \\ 素材 3D模型展示平台，部分作者开放作品的下载。   turbosquid.com 3D 素材 免费3D模型搜索与下载。   cgtrader.com 3D 素材 免费3D模型搜索与下载。   3dwarehouse.sketchup.com 3D 素材 SketchUp的模型库，建筑模型居多。   www6.atwiki.jp/vpvpwiki/ 3D 素材 MMD维基，分类整理了大量MMD模型的配布情况。   blendswap.com 3D 作品 \\ 教程 \\ 素材 Blender的社区，经验交流与资源下载都有。   blenderartists.org 3D 作品 \\ 教程 Blender的社区，更侧重经验交流。   blendercn.org 3D 作品 \\ 教程 Blender中文社区，提供新闻、教程与电子杂志。   3dtextures.me 3D 素材 免费3D材质贴图。   textures.com 3D 素材 材质有关的照片素材和3D贴图。   hdrihaven.com 3D 素材 材质贴图和天空球。   mixamo.com 3D 素材 \\ 服务 Adobe提供的自动人物模型绑骨服务，同时有大量3D动作数据供下载。   mocap.cs.cmu.edu 3D 素材 卡内基梅隆大学的动作捕捉数据库。   pexels.com 图片 \\ 视频 素材 免费图片与视频素材。   freestocktextures.com 图片 素材 材质照片素材（非3D）。   stocksnap.io 图片 素材 免费照片素材。   vecteezy.com 图片 \\ 视频 素材 图片和视频素材、笔刷。   digitaltone-studio.com 图片 素材 漫画素材、网点，部分免费。   tinryu.sarashi.com 图片 素材 以用于绘画的纹理素材为主。   ikiya.jp 图片 素材 和风纹理素材、配色。   librestock.com 图片 素材 免费图片的搜索引擎，可以从其他一些网站寻找免费资源。   pixabay.com 图片 \\ 视频 素材 免费照片、矢量图与视频素材。   vegasaur.com 视频 素材 \\ 插件 提供免费的视频素材与Vegas插件预置。   newcger.com 视频 作品 \\ 教程 \\ 素材 视频素材和After Effects模板，但相当一部分资源的正当性存疑。   videvo.net 视频 \\ 音频 素材 免费视频、音乐、声效素材。   productioncrate.com 图片 \\ 视频 \\ 音频 素材 现成的特效或是素材都有提供。只有一部分免费，不过质量不错。   opengameart.org 图片 \\ 音频 素材 分享制作游戏需要的素材，其中美术多为像素风格。   soundbible.com 音频 素材 免费声效素材。   amachamusic.chagasi.com 音频 素材 免费背景音乐。   utaforum.net 音频 插件 \\ 教程 UTAU的经验交流与插件下载。   dskmusic.com 音频 插件 多种免费VST插件，采样乐器居多。   kvraudio.com 音频 插件 可分类搜索VST插件，相当一部分为免费。   midifan.com 音频 教程 中文网站，提供音乐制作方面的新闻与教程。   vst4free.com 音频 插件 多种免费VST插件。   trisamples.com 音频 素材 \\ 插件 SoundFont和采样包。   landr.com 音频 素材 免费采样包。   musical-artifacts.com 音频 素材 免费音色采样。   hooktheory.com 音频 教程 流行歌曲的和弦进行分析，同时还可以反过来按照和弦进行搜索歌曲。   xen.wiki 音频 教程 \\ 插件 记录非传统音律的维基，如微分音等，总结了理论和创作工具。                                                                                 ","id":15,"section":"posts","summary":"\u003cul\u003e\n\u003cli\u003e本页面搜集整理网络上可用于多媒体制作的免费资源，自身并不提供资源的下载。\u003c/li\u003e\n\u003cli\u003e部分条目使用\u003cstrong\u003e粗体\u003c/strong\u003e标记，表示笔者自身使用该工具/服务的频率较高，是完全主关的评价。本站其他文章也可能会更频繁地涉及到它们。\u003c/li\u003e\n\u003cli\u003e被列举的网站除免费资源外，可能也提供收费资源。此外，资源的使用遵循不同种类的协议，需要使用者自行鉴别。\u003c/li\u003e\n\u003cli\u003e本页面将不定期更新，移除失效链接。部分网站可能有访问区域限制，笔者没有精力逐一验证并注明，还请见谅。\u003c/li\u003e\n\u003c/ul\u003e","tags":["资源汇总"],"title":"资源网站汇总","uri":"https://chaosinism.github.io/posts/website-list/","year":"2019"},{"content":" 本页面列举笔者体验过的开源或免费软件、工具，主要侧重于多媒体制作（包含绘图、3D、视频、音乐等）相关的功能。 部分条目使用粗体标记，表示笔者自身使用该工具/服务的频率较高，是完全主关的评价。本站其他文章也可能会更频繁地涉及到它们。 表格中部分软件存在收费版本，但与免费版本的区别仅在于功能强弱，在使用时限、导入导出等关键要素上不存在限制。     名称 类别 链接 简介     Blender 3D, 视频 官网 主要是3D软件，实际上和视频沾边的工作基本都可以做。内置大量插件，下面介绍的是未内置的插件。   - 插件 - MMD Tools  源码 在Blender中导入或导出MMD模型与动作。   - 插件 - Animation Nodes  源码 扩展了Blender的动画功能。   - 插件 - VSE Transform Tools  源码 扩展了Blender的视频剪辑功能。   - 插件 - Armory3D  官网 提供逻辑功能，可以直接用Blender生成互动应用和游戏。   MikuMikuDance 3D 官网 相信不需太多介绍。   MikuMikuMoving 3D 官网 MMD的另一选择，有额外的功能，但不兼容大部分MME，可以单独用于K帧。   PmxEditor 3D 官网 MMD模型的编辑器。   OpenMMD 3D 源码 建立在OpenPose的基础上，利用深度学习对视频或图片进行姿势与深度识别，并生成MMD动作文件。   ALP2PMX 3D  将TEATIME出品的游戏中捏的人物提取为MMD模型。游戏本体并非免费，但非商业用途的MMD模型好像也不怎么被追究的样子。   MakeHuman 3D 官网 生成写实风格的3D人体模型。   FaceGen 3D 官网 根据人脸照片自动生成人头3D模型，免费版有水印，但不难去掉。   Meshroom 3D 官网 根据多个角度拍摄的物体照片自动生成该物体的3D模型。   VRoid Studio 3D 官网 动漫风格的捏人工具，制作头发比较方便，但多边形数很高，有时需要再用别的软件优化。   Sweet Home 3D 3D 官网 开源室内设计软件，可生成低多边形的房间3D模型。   AwesomeBump 3D 源码 处理3D贴图，包括凹凸、法线、AO、反射等贴图种类。   DeepNormals 3D, 绘画 源码 利用深度学习，自动由二维绘画估计出法线贴图，可以用于辅助上色。   Aviutl 视频 官网 免费的视频编辑软件，可做MAD、PV等。   EbSynth 视频 官网 自动视频风格迁移，提供关键帧即可将整段视频风格化。   PhotoAnim 视频 官网 为单张静态图片生成骨骼动画和简单的3D模型等的工具。   GIMP 图像处理 官网 开源图像处理软件，功能类似Photoshop。   - 插件 - G\u0026rsquo;mic  官网 提供大量图片滤镜、特效，除了作为插件，也可以独立运行。   - 插件 - Resynthesizer  官网 类似Photoshop的智能填充功能。   MediBang Paint 绘画 官网 免费的绘画软件，除桌面版外也有iOS和安卓版，并且提供云储存以便随时在不同的平台之间切换。   Inkscape 绘画 官网 矢量图绘画软件。   Style2paints 绘画 源码 国人的深度学习自动上色项目，大部分情况下效果优于同类的PaintsChainer。   Audacity 音频 官网 开源音频处理软件，擅长处理波形文件，类似Audition。支持VST和其他各种插件。   UTAU 音频 官网 歌声合成工具，比较容易自制音源。   VocalShifter 音频 官网 音频处理软件，比较突出的功能是类似Melodyne的变调。   MixMeister BPM Analyzer 音频 官网 测歌曲的BPM，现在收费了，但免费的旧版仍能在网上找到。   LMMS 音频 官网 开源的DAW，操作类似FL Studio。   - 插件 - DSK系列  官网 提供各种免费乐器插件，包括中国乐器。   - 插件 - VSCO2  官网 管弦乐器采样。   - 插件 - Alter/Ego  官网 支持英语和日语的歌声合成引擎，使用的是90年代较旧的技术。   - 插件 - Paraphrasis  官网 采样插件，变调不变速，做音MAD可能有帮助。   - 插件 - Synth1  官网 虽然很旧，但是较流行的免费合成器，网上可找到很多预置音色。   - 插件 - MFreeFXBundle  官网 一系列常用的效果插件，其中卷积混响插件是个亮点。   - 插件 - ReaPlugs  官网 REAPER将自己的功能做成其他DAW也可使用的VST，亮点是支持实时JS脚本的ReaJS。   LoopBe1 音频 官网 可以在没有MIDI硬件的情况下将软件的MIDI接口连接到其他软件。   Vmpk 音频 官网 虚拟键盘，配合LoopBe1可以把触屏当成MIDI键盘使用。   Impro-Visor 音频 官网 自动生成爵士乐风格的自动伴奏，既可用于乐理学习，也可辅助音乐制作。   Spleeter 音频 源码 基于机器学习的人声提取/音轨分离工具。   Magenta Studio 音频 官网 一套使用机器学习来辅助作曲/编曲的工具，但目前实用性还很有限。   Construct 2 游戏 官网 HTML5游戏引擎，不需要编程就可以制作网页应用和游戏。免费版有一些功能限制。   Godot 游戏 官网 支持各种语言与平台的开源游戏引擎。                                                                                             ","id":16,"section":"posts","summary":"\u003cul\u003e\n\u003cli\u003e本页面列举笔者体验过的开源或免费软件、工具，主要侧重于多媒体制作（包含绘图、3D、视频、音乐等）相关的功能。\u003c/li\u003e\n\u003cli\u003e部分条目使用\u003cstrong\u003e粗体\u003c/strong\u003e标记，表示笔者自身使用该工具/服务的频率较高，是完全主关的评价。本站其他文章也可能会更频繁地涉及到它们。\u003c/li\u003e\n\u003cli\u003e表格中部分软件存在收费版本，但与免费版本的区别仅在于功能强弱，在使用时限、导入导出等关键要素上不存在限制。\u003c/li\u003e\n\u003c/ul\u003e","tags":["资源汇总"],"title":"软件与工具汇总","uri":"https://chaosinism.github.io/posts/tool-list/","year":"2019"},{"content":"个人简介 兴趣是动漫作品的二次创作和亚文化相关创作。本博客记录一些个人的创作体会与经验。并非专业人士，无法保证所记载内容完全准确，如有错漏欢迎指正。\n联系方式  Bilibili: https://space.bilibili.com/89358 itch.io: https://itch.io/profile/chaosinism Niconico: https://www.nicovideo.jp/user/31807351 Pixiv: https://www.pixiv.net/member.php?id=5104337 DeviantArt: https://www.deviantart.com/chaosinism （暂无余力更新） Discord: chaosinism#3933 ","id":17,"section":"posts","summary":"","tags":null,"title":"关于我","uri":"https://chaosinism.github.io/posts/about-me/","year":"2019"}],"tags":[{"title":"Blender","uri":"https://chaosinism.github.io/tags/blender/"},{"title":"C++","uri":"https://chaosinism.github.io/tags/c++/"},{"title":"C Sharp","uri":"https://chaosinism.github.io/tags/c-sharp/"},{"title":"Godot","uri":"https://chaosinism.github.io/tags/godot/"},{"title":"JavaScript","uri":"https://chaosinism.github.io/tags/javascript/"},{"title":"Kinect","uri":"https://chaosinism.github.io/tags/kinect/"},{"title":"LMMS","uri":"https://chaosinism.github.io/tags/lmms/"},{"title":"MIDI","uri":"https://chaosinism.github.io/tags/midi/"},{"title":"MMD","uri":"https://chaosinism.github.io/tags/mmd/"},{"title":"Python","uri":"https://chaosinism.github.io/tags/python/"},{"title":"UTAU","uri":"https://chaosinism.github.io/tags/utau/"},{"title":"Vegas","uri":"https://chaosinism.github.io/tags/vegas/"},{"title":"VRoid","uri":"https://chaosinism.github.io/tags/vroid/"},{"title":"东方Project","uri":"https://chaosinism.github.io/tags/%E4%B8%9C%E6%96%B9project/"},{"title":"机器学习","uri":"https://chaosinism.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"title":"独人13","uri":"https://chaosinism.github.io/tags/%E7%8B%AC%E4%BA%BA13/"},{"title":"独立游戏","uri":"https://chaosinism.github.io/tags/%E7%8B%AC%E7%AB%8B%E6%B8%B8%E6%88%8F/"},{"title":"资源汇总","uri":"https://chaosinism.github.io/tags/%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB/"},{"title":"软件脚本","uri":"https://chaosinism.github.io/tags/%E8%BD%AF%E4%BB%B6%E8%84%9A%E6%9C%AC/"},{"title":"音MAD","uri":"https://chaosinism.github.io/tags/%E9%9F%B3mad/"},{"title":"驱动","uri":"https://chaosinism.github.io/tags/%E9%A9%B1%E5%8A%A8/"}]}