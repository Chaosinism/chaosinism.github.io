<!DOCTYPE html>
<html class="no-js" lang="zh-CN">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>利用语音识别技术辅助制作音源的初步尝试 - 临时个人主页</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
	<meta property="og:title" content="利用语音识别技术辅助制作音源的初步尝试" />
<meta property="og:description" content="若想由一段音频素材（如一首歌或一段对话）制作出供人力Vocaloid使用的音源，第一步是要在素材中把可以用的发音逐个截取出来，此过程通常较为枯燥费力。因此，本文尝试探索一种结合AI语音识别技术加速该过程的方法。下面介绍一下步骤与工具。

需注意，本文原始发布时间较早，仅对此问题进行了初步的探索，并未得到一个成熟的解决方案，效果远非理想。另外，目前没有很方便的图形界面来实现文中所述功能，因此建议在对命令行与Python有一定使用经验的前提下阅读。

（原始投稿地址：https://www.bilibili.com/read/cv465184 ）" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/posts/voice-extraction/" />
<meta property="article:published_time" content="2019-08-31T06:52:47-04:00" />
<meta property="article:modified_time" content="2019-08-31T06:52:47-04:00" />

	
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">
	<link rel="stylesheet" href="/css/style.css">
	
	<link rel="shortcut icon" href="/favicon.ico">
		
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-145442293-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container">
		<div class="logo">
			<a class="logo__link" href="/" title="临时个人主页" rel="home">
				<div class="logo__title">临时个人主页</div>
				
				
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-145442293-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

			</a>
		</div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			<a class="menu__link" href="/posts/about-me/">关于我</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/posts/tiny-games/">在线小游戏</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/posts/homemade/">自制资源汇总</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/posts/website-list/">资源网站汇总</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/posts/tool-list/">软件与工具汇总</a>
		</li>
	</ul>
</nav>

	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">利用语音识别技术辅助制作音源的初步尝试</h1>
			
		</header>
<div class="post__toc toc">
	<div class="toc__title">Page content</div>
	<div class="toc__menu">
		<nav id="TableOfContents">
<ul>
<li>
<ul>
<li><a href="#watson-speech-to-text-的使用方法">Watson Speech to Text 的使用方法</a></li>
<li><a href="#提取json文件的数据并进行音频分割">提取JSON文件的数据并进行音频分割</a></li>
<li><a href="#注意事项">注意事项</a></li>
<li><a href="#结论与反思">结论与反思</a></li>
</ul></li>
</ul>
</nav>
	</div>
</div>
<div class="content post__content clearfix">
			<p>若想由一段音频素材（如一首歌或一段对话）制作出供人力Vocaloid使用的音源，第一步是要在素材中把可以用的发音逐个截取出来，此过程通常较为枯燥费力。因此，本文尝试探索一种结合AI语音识别技术加速该过程的方法。下面介绍一下步骤与工具。</p>

<p>需注意，本文原始发布时间较早，仅对此问题进行了初步的探索，并未得到一个成熟的解决方案，效果远非理想。另外，目前没有很方便的图形界面来实现文中所述功能，因此建议在对命令行与Python有一定使用经验的前提下阅读。</p>

<p>（原始投稿地址：<a href="https://www.bilibili.com/read/cv465184">https://www.bilibili.com/read/cv465184</a> ）</p>

<p><center><figure>
    <img src="1.png"
         alt="目标：自动得到一系列单音节发音的wav文件" width="500px"/> <figcaption>
            <p>目标：自动得到一系列单音节发音的wav文件</p>
        </figcaption>
</figure>
</center></p>

<h2 id="watson-speech-to-text-的使用方法">Watson Speech to Text 的使用方法</h2>

<p>本步骤使用IBM的语音识别应用来获得每个单词在音频中的位置（起始时间与终止时间），以便之后的截取。</p>

<p>在这个网址注册IBM账号并申请该应用：<a href="https://www.ibm.com/watson/services/speech-to-text/">https://www.ibm.com/watson/services/speech-to-text/</a></p>

<p><center><figure>
    <img src="2.png"
         alt="点击左侧按钮即可注册" width="500px"/> <figcaption>
            <p>点击左侧按钮即可注册</p>
        </figcaption>
</figure>
</center>
注册成功后，目前可获得<strong>每月100分钟</strong>的免费额度，并得到用户名与密码。与注册时输入的用户名密码不同，它们是专门用于语音识别服务的。</p>

<p><center><figure>
    <img src="3.png"
         alt="点击“显示”可看到用户名和密码" width="800px"/> <figcaption>
            <p>点击“显示”可看到用户名和密码</p>
        </figcaption>
</figure>
</center>
IBM提供一系列API来调用语音识别应用，其中通过HTTP是比较便捷的一种方法。如果是Linux等系统，可以在命令行中使用如下形式的curl命令；如果是Windows系统，可能需要先下载curl（<a href="https://curl.haxx.se）：">https://curl.haxx.se）：</a></p>

<pre><code class="language-shell">curl -X POST -u &quot;你的用户名&quot;:&quot;你的密码&quot; --header &quot;Content-Type: audio/wav&quot; --data-binary &quot;@你的音频素材文件.wav&quot; &quot;https://stream.watsonplatform.net/speech-to-text/api/v1/recognize?model=zh-CN_BroadbandModel&amp;word_confidence=true&amp;timestamps=true&quot; --output curl_result.json
</code></pre>

<p>介绍一下涉及到的选项：</p>

<ul>
<li><strong>Content-Type: audio/wav：</strong> 指明文件类型，最好使用单通道的wav文件，另外对采样率也有要求，下面会解释。</li>
<li><strong>model=zh-CN_BroadbandModel</strong>：指明语言是中文，这里Broadband对应16000Hz采样率，另有Narrowband对应8000Hz采样率。除中文外，也支持识别其他语言，如日语可以用ja-JP_BroadbandModel，英式英语en-GB_BroadbandModel，美式英语en-US_BroadbandModel等。</li>
<li><strong>word_confidence=true：</strong>AI对识别出的每个单词有一个置信度（0~1），越接近1表明识别越准确。</li>
<li><strong>timestamps=true：</strong>每个单词在音频中的起始与终止秒数，这是我们最需要的数据。</li>
</ul>

<p>若不出意外，等待几分钟后会有一个curl_result.json文件被下载，其中就是语音所对应的文字，与我们需要的时间数据。</p>

<h2 id="提取json文件的数据并进行音频分割">提取JSON文件的数据并进行音频分割</h2>

<p>得到json文件后，就可以按照里面提供的时间信息来切割原本的音频素材。我写了一个简单的Python脚本来执行这个操作，在这里分享一下:</p>

<ul>
<li><a href="https://github.com/Chaosinism/utau_tools">https://github.com/Chaosinism/utau_tools</a></li>
</ul>

<p>将代码中的文件名换成对应的wav与json文件，执行就可以得到分割后的多个发音。</p>

<p>脚本主要用到这些库：</p>

<ul>
<li><strong>json</strong>： 用于读取json格式的数据。</li>
<li><strong>wave</strong>：用于读取并操作wav文件。</li>
<li><strong>scipy</strong>：著名的科学计算工具，此处用于辅助操作wav文件。</li>
<li><strong>pypinyin</strong>：将汉字转换为拼音，用于为切割后的文件命名。</li>
</ul>

<p>此脚本仅能用于中文音频，但其他语言也大同小异，稍作修改即可。默认情况下脚本输出全部被识别出的发音，其中一些可能并不正确或不适合作为音源，可以设置confidence_threshold变量以仅仅输出置信度较高的发音。</p>

<h2 id="注意事项">注意事项</h2>

<ul>
<li>获得发音文件仅是音源制作的第一步，需要后续手动调整来提高音源质量。以UTAU为例，oto.in并不会自动生成，需要在UTAU中手动设置，或使用setParam来辅助设置。</li>
<li>请勿将本文中介绍的方法用于非法用途。</li>
</ul>

<h2 id="结论与反思">结论与反思</h2>

<p>此次尝试较为肤浅，效果也有限，经简单测试，提取出的发音只有不到一半可用。目前各大厂商提供的语音识别模型有很大比重是对语义的判断，而从制作音源的角度来看，仅需要对单个发音的识别，词句级别的识别与上下文都是不必要的，所以也许反而应该使用更原始的模型。我也尝试使用可自行定制的离线语音识别系统，如CMU Sphinx，但效果更差。若有改进建议或是其它想法，欢迎交流讨论。</p>
		</div>
		<footer class="post__footer">
			
<div class="post__tags tags clearfix">
	<svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item"><a class="tags__link btn" href="/tags/utau/" rel="tag">UTAU</a></li>
		<li class="tags__item"><a class="tags__link btn" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">机器学习</a></li>
		<li class="tags__item"><a class="tags__link btn" href="/tags/python/" rel="tag">Python</a></li>
	</ul>
</div>
		</footer>
	</article>
</main>


<nav class="post-nav flex">
	<div class="post-nav__item post-nav__item--prev">
		<a class="post-nav__link" href="/posts/kinect-mmd/" rel="prev"><span class="post-nav__caption">«&thinsp;Previous</span><p class="post-nav__post-title">Kinect v2与MMD动作捕捉</p></a>
	</div>
	<div class="post-nav__item post-nav__item--next">
		<a class="post-nav__link" href="/posts/blog-setup/" rel="next"><span class="post-nav__caption">Next&thinsp;»</span><p class="post-nav__post-title">搭建个人主页的心得</p></a>
	</div>
</nav>
  <h2>评论</h2>
  
  
  

  
    
  
    
  
    
      
      
<blockquote>
  <p>&ldquo;你的用户名&rdquo;:&ldquo;你的密码&rdquo; 现在改成了&rdquo;apikey:{apikey}&rdquo;</p>
  <cite>
    <strong>评论人： </strong>Loyisa<br><strong>发表日期： </strong>14/09/2019  
</cite>
</blockquote>
             
    
  

  




<form method="POST" action="https://staticman3.herokuapp.com/v2/entry/Chaosinism/chaosinism.github.io/master/comments">
    <input type="hidden" name="options[redirect]" value="https://chaosinism.github.io">
    <input type="hidden" name="options[slug]" value="voice-extraction">
    <input type="hidden" name="options[parent]" value="voice-extraction">
    <input name="fields[name]" type="text" placeholder="昵称（必填）">
    <input name="fields[email]" type="email" placeholder="邮箱（选填）">
    <textarea name="fields[message]" placeholder="请输入留言内容（支持Markdown语法）。留言经博主审核后显示在网页上，此外可在本站Github仓库检查已提交的留言。" rows="10"></textarea>
    <input type="submit" value="提交">
  </form>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2020 临时个人主页.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/js/menu.js"></script></body>
</html>